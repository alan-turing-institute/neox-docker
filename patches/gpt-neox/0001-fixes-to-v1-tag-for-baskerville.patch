From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Ed Chapman <idyn7568@bask-pg-login02.cluster.baskerville.ac.uk>
Date: Wed, 14 Aug 2024 10:31:00 +0100
Subject: [PATCH] fixes to v1 tag for baskerville

---
 megatron/model/transformer.py        | 2 +-
 megatron/neox_arguments/arguments.py | 3 +++
 requirements/requirements.txt        | 2 +-
 tools/convert_to_hf.py               | 4 ++--
 4 files changed, 7 insertions(+), 4 deletions(-)

diff --git a/megatron/model/transformer.py b/megatron/model/transformer.py
index d1be347f..019404c8 100644
--- a/megatron/model/transformer.py
+++ b/megatron/model/transformer.py
@@ -429,7 +429,7 @@ class ParallelSelfAttention(nn.Module):
         )
 
         # Combined q/k/v into [b * s, 3, np, hn].
-        qkv = torch.concat([query_layer, key_layer, value_layer], dim=1)
+        qkv = torch.cat([query_layer, key_layer, value_layer], dim=1)
 
         batch_size = output_size[0]
         seqlen = output_size[2]
diff --git a/megatron/neox_arguments/arguments.py b/megatron/neox_arguments/arguments.py
index 4ab9a63e..cb09356c 100644
--- a/megatron/neox_arguments/arguments.py
+++ b/megatron/neox_arguments/arguments.py
@@ -406,6 +406,9 @@ class NeoXArgs(*BASE_CLASSES):
                     self.convert_key_value_to_command_line_arg(key, configured_value)
                 )
 
+        # Ed: Include this arg for single node slurm or mpi launching **only**
+        # args_list.extend(self.convert_key_value_to_command_line_arg("force_multi",True))
+
         if "DLTS_HOSTFILE" in os.environ:
             args_list.extend(
                 self.convert_key_value_to_command_line_arg(
diff --git a/requirements/requirements.txt b/requirements/requirements.txt
index 6d30d1a5..ba267ec4 100644
--- a/requirements/requirements.txt
+++ b/requirements/requirements.txt
@@ -4,7 +4,7 @@ ftfy==6.0.1
 git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836
 huggingface_hub==0.11.0
 lm_eval==0.3.0
-mpi4py==3.0.3
+mpi4py==3.1.3
 numpy==1.22.0
 pybind11==2.6.2
 regex
diff --git a/tools/convert_to_hf.py b/tools/convert_to_hf.py
index bf989abd..de333345 100644
--- a/tools/convert_to_hf.py
+++ b/tools/convert_to_hf.py
@@ -18,7 +18,7 @@ import sys
 import yaml
 import argparse
 from tqdm import tqdm
-
+from typing import List
 import torch
 from transformers import GPTNeoXConfig, GPTNeoXForCausalLM
 
@@ -41,7 +41,7 @@ Please investigate carefully whether your model is compatible with all architect
 
 def load_partitions(
     input_checkpoint_path, mp_partitions, layer_idx
-) -> list[torch.Tensor]:
+) -> List[torch.Tensor]:
     """Returns a list containing all weights in a given layer from a model (across MP partitions)"""
 
     loaded_tp_ranks = [
